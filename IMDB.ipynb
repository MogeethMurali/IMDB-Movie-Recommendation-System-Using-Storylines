import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

def click_load_more(driver):
    try:
        load_more_button = WebDriverWait(driver, 10).until(
            EC.presence_
            of_element_located((By.XPATH, '//*[@id="__next"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button/span/span'))
        )
        ActionChains(driver).move_to_element(load_more_button).perform()
        load_more_button.click()
        time.sleep(3)
        return True
    except Exception as e:
        print(f"Error clicking 'Load More' button:", e)
        return False

def scrape_crime_movies(url, max_count=1500):
    driver = webdriver.Chrome()
    driver.get(url)

    movie_data = []
    scraped_count = 0
    page_count = 0

    while scraped_count < max_count:
        try:
            print(f"Scraping batch {page_count + 1}...")

            movie_elements = WebDriverWait(driver, 15).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.ipc-metadata-list-summary-item'))
            )

            for movie_element in movie_elements:
                if scraped_count >= max_count:
                    break
                try:
                    title_element = movie_element.find_element(By.CSS_SELECTOR, '.ipc-title a')
                    movie_name = title_element.text.strip()

                    storyline = ""
                    storyline_elements = movie_element.find_elements(By.CSS_SELECTOR, '.ipc-html-content-inner-div')
                    if storyline_elements:
                        storyline = storyline_elements[0].text.strip()

                    if movie_name and storyline:
                        movie_data.append({
                            'Movie Name': movie_name,
                            'Storyline': storyline
                        })
                        scraped_count += 1
                        print(f"Scraped: {movie_name} ({scraped_count})")

                except Exception as e:
                    print(f"Error extracting movie: {e}")

            if not click_load_more(driver):
                print("No more content to load.")
                break

            page_count += 1

        except Exception as e:
            print(f"Error on batch {page_count + 1}: {e}")
            break

    driver.quit()
    return pd.DataFrame(movie_data)

def save_data(df, filename="imdb_movies.csv"):
    df.to_csv(filename, index=False, encoding='utf-8')
    print(f"Saved {len(df)} entries to {filename}")

if __name__ == "__main__":
    imdb_url = "https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&user_rating=1,&adult=include&sort=release_date,desc" # Modified URL to only include crime
    movie_limit = 8000  # Increased the movie limit

    df = scrape_crime_movies(imdb_url, movie_limit)
    if not df.empty:
        save_data(df)
    else:
        print("No movie data was scraped.")
